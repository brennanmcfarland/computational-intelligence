{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load our inputs and targets from the corresponding csv files into numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 12)\n",
      "[[3.         4.         1.         ... 0.57142857 0.40765391 1.        ]\n",
      " [7.         4.         1.         ... 1.         0.66139767 0.5       ]\n",
      " [2.         1.         0.         ... 0.57142857 0.71214642 0.33333333]\n",
      " ...\n",
      " [7.         4.         1.         ... 0.71428571 0.36439268 1.        ]\n",
      " [6.         4.         1.         ... 0.57142857 0.42845258 0.33333333]\n",
      " [1.         3.         0.         ... 0.57142857 0.68053245 0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = np.genfromtxt('basf_inputs_rand_normalized.csv', delimiter=',')\n",
    "print(raw_inputs.shape)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 1)\n",
      "[[0.33097762]\n",
      " [0.26266196]\n",
      " [0.10600707]\n",
      " ...\n",
      " [0.34393404]\n",
      " [0.02120141]\n",
      " [0.29799764]]\n"
     ]
    }
   ],
   "source": [
    "raw_targets = np.genfromtxt('basf_targets_rand_normalized.csv', delimiter=',')\n",
    "raw_targets = np.expand_dims(raw_targets, axis=1) # because tensorflow wants each column in an array even if only 1 value\n",
    "print(raw_targets.shape)\n",
    "print(raw_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the first four columns of feature data are converted to one-hot values, done prior to splitting into training, validation and testing sets for the sake of reducing redundancy and for efficiency. The first four columns have 8, 4, 2, and 5 different possible values respectively, so that will be the dimension of each one-hot vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 7. 2. ... 7. 6. 1.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "[4. 4. 1. ... 4. 4. 3.]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "[1. 1. 0. ... 1. 1. 0.]\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "[1. 3. 0. ... 3. 3. 2.]\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "num_col_values = (8, 4, 2, 5)\n",
    "new_cols = []\n",
    "for col in range(4):\n",
    "    col_values = raw_inputs[:, col]\n",
    "    print(col_values)\n",
    "    col_values = tf.cast(col_values, tf.int32)\n",
    "    col_one_hot = tf.one_hot(col_values, num_col_values[col])\n",
    "    print(sess.run(col_one_hot))\n",
    "    new_cols.append(col_one_hot)\n",
    "new_cols.append(raw_inputs[:, 4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.5714286  0.4076539  1.        ]\n",
      " [0.         0.         0.         ... 1.         0.6613977  0.5       ]\n",
      " [0.         0.         1.         ... 0.5714286  0.7121464  0.33333334]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.71428573 0.36439267 1.        ]\n",
      " [0.         0.         0.         ... 0.5714286  0.42845258 0.33333334]\n",
      " [0.         1.         0.         ... 0.5714286  0.68053246 0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.concat(new_cols, axis=1)\n",
    "targets = raw_targets\n",
    "print(sess.run(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll reserve 80% of the data for training and 10% for validation and testing, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029\n",
      "Tensor(\"strided_slice_7:0\", shape=(823, 27), dtype=float32)\n",
      "Tensor(\"strided_slice_8:0\", shape=(103, 27), dtype=float32)\n",
      "Tensor(\"strided_slice_9:0\", shape=(103, 27), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "training_bound = int(int(inputs.shape[0])*.8)\n",
    "validation_bound = int(int(inputs.shape[0])*.9)\n",
    "training_inputs, training_targets = inputs[:training_bound], targets[:training_bound]\n",
    "validation_inputs, validation_targets = inputs[training_bound:validation_bound], targets[training_bound:validation_bound]\n",
    "testing_inputs, testing_targets = inputs[validation_bound:], targets[validation_bound:]\n",
    "print(int(training_inputs.shape[0])+ int(validation_inputs.shape[0]) + int(testing_inputs.shape[0])) # verify number examples preserved\n",
    "print(training_inputs)\n",
    "print(validation_inputs)\n",
    "print(testing_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27,)\n"
     ]
    }
   ],
   "source": [
    "# get the shape of the input to give to the model\n",
    "print(training_inputs[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=int(training_inputs[0].shape[0]), activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stochastic gradient descent as the optimizer\n",
    "optimizer = SGD(lr=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping callback to stop when validation loss stops improving\n",
    "early_stopping = EarlyStopping(monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: mess with these\n",
    "steps_per_epoch = 10\n",
    "validation_steps = 10\n",
    "testing_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(823, 1)\n",
      "Train on 823 samples, validate on 103 samples\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0822 - val_loss: 0.0501\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0454\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0400 - val_loss: 0.0434\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0375 - val_loss: 0.0422\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0359 - val_loss: 0.0414\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0348 - val_loss: 0.0407\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0338 - val_loss: 0.0401\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0330 - val_loss: 0.0395\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0324 - val_loss: 0.0389\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0317 - val_loss: 0.0384\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0311 - val_loss: 0.0378\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0306 - val_loss: 0.0371\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0364\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0356\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0349\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0283 - val_loss: 0.0342\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0335\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0327\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0320\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0313\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0306\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 0.0299\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.0292\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.024 - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0284\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0234 - val_loss: 0.0277\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0229 - val_loss: 0.0270\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0224 - val_loss: 0.0263\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0219 - val_loss: 0.0256\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0250\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.0243\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0204 - val_loss: 0.0236\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.0230\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0224\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0218\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0212\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0206\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0175 - val_loss: 0.0201\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0195\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0190\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0185\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0170\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0166\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0157\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0152\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0140\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0137\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0133\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0129\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0123\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0089\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.007 - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a77bc9c5f8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(training_targets.shape)\n",
    "model.fit(\n",
    "    training_inputs,\n",
    "    training_targets,\n",
    "    validation_data = (validation_inputs, validation_targets),\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    validation_steps = validation_steps,\n",
    "    callbacks=[early_stopping],\n",
    "    epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-training loss on test data:  0.007156532257795334\n"
     ]
    }
   ],
   "source": [
    "testing_loss = model.evaluate(\n",
    "    testing_inputs,\n",
    "    testing_targets,\n",
    "    steps = testing_steps,\n",
    "    verbose = 0)\n",
    "print(\"Post-training loss on test data: \", testing_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 823 samples, validate on 103 samples\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.0834 - val_loss: 0.0613\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0521 - val_loss: 0.0475\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0402 - val_loss: 0.0431\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.0403\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0334 - val_loss: 0.0382\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0315 - val_loss: 0.0362\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0299 - val_loss: 0.0344\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0286 - val_loss: 0.0328\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0274 - val_loss: 0.0314\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0264 - val_loss: 0.0300\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 0.0287\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0245 - val_loss: 0.0275\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0236 - val_loss: 0.0263\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.0252\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0219 - val_loss: 0.0241\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0212 - val_loss: 0.0231\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0204 - val_loss: 0.0221\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.0212\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0195\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0186\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0178\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0170\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0163\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0156\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0134\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0129\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0088\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0086\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0080\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0076\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0064\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Post-training loss on test data:  0.004730306565761566\n"
     ]
    }
   ],
   "source": [
    "modelB = Sequential()\n",
    "modelB.add(Dense(16, input_dim=int(training_inputs[0].shape[0]), activation='relu'))\n",
    "modelB.add(Dense(16, activation='relu'))\n",
    "modelB.add(Dense(1, activation='relu'))\n",
    "modelB.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "modelB.fit(\n",
    "    training_inputs,\n",
    "    training_targets,\n",
    "    validation_data = (validation_inputs, validation_targets),\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    validation_steps = validation_steps,\n",
    "    callbacks=[early_stopping],\n",
    "    epochs=1000)\n",
    "testing_loss = modelB.evaluate(\n",
    "    testing_inputs,\n",
    "    testing_targets,\n",
    "    steps = testing_steps,\n",
    "    verbose = 0)\n",
    "print(\"Post-training loss on test data: \", testing_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 823 samples, validate on 103 samples\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.1179 - val_loss: 0.1311\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.1311\n",
      "Post-training loss on test data:  0.1007809191942215\n"
     ]
    }
   ],
   "source": [
    "modelC = Sequential()\n",
    "modelC.add(Dense(16, input_dim=int(training_inputs[0].shape[0]), activation='relu'))\n",
    "modelC.add(Dense(1, activation='relu'))\n",
    "modelC.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "modelC.fit(\n",
    "    training_inputs,\n",
    "    training_targets,\n",
    "    validation_data = (validation_inputs, validation_targets),\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    validation_steps = validation_steps,\n",
    "    callbacks=[early_stopping],\n",
    "    epochs=1000)\n",
    "testing_loss = modelC.evaluate(\n",
    "    testing_inputs,\n",
    "    testing_targets,\n",
    "    steps = testing_steps,\n",
    "    verbose = 0)\n",
    "print(\"Post-training loss on test data: \", testing_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 823 samples, validate on 103 samples\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.0852 - val_loss: 0.0893\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0694 - val_loss: 0.0826\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0612 - val_loss: 0.0739\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0531 - val_loss: 0.0639\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0462 - val_loss: 0.0577\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0425 - val_loss: 0.0544\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0407 - val_loss: 0.0527\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0396 - val_loss: 0.0516\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0389 - val_loss: 0.0509\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0384 - val_loss: 0.0504\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0380 - val_loss: 0.0499\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0376 - val_loss: 0.0496\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0372 - val_loss: 0.0492\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0369 - val_loss: 0.0488\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0366 - val_loss: 0.0484\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0363 - val_loss: 0.0480\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0361 - val_loss: 0.0476\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0358 - val_loss: 0.0473\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0356 - val_loss: 0.0469\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0353 - val_loss: 0.0465\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0350 - val_loss: 0.0462\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0347 - val_loss: 0.0459\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0344 - val_loss: 0.0456\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0341 - val_loss: 0.0453\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0338 - val_loss: 0.0450\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0336 - val_loss: 0.0447\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0333 - val_loss: 0.0445\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0329 - val_loss: 0.0441\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0326 - val_loss: 0.0436\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0322 - val_loss: 0.0429\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0318 - val_loss: 0.0423\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0314 - val_loss: 0.0416\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0309 - val_loss: 0.0408\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0305 - val_loss: 0.0400\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0301 - val_loss: 0.0393\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0296 - val_loss: 0.0386\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0292 - val_loss: 0.0380\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0373\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0283 - val_loss: 0.0367\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0362\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0274 - val_loss: 0.0355\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.0347\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0263 - val_loss: 0.0338\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0256 - val_loss: 0.0327\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0247 - val_loss: 0.0311\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0235 - val_loss: 0.0293\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0222 - val_loss: 0.0277\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0210 - val_loss: 0.0264\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.0253\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0242\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0231\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0221\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0212\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0203\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0195\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0188\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0180\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0173\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0166\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0160\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0154\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0148\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0143\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0138\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0129\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0125\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0122\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0118\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0115\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0112\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0098\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0096\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0094\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0091\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0089\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0087\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0086\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0082\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0075\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0073\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0072\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0070\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0069\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0068\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0068\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0067\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0066\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0066\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0065\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 161/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Post-training loss on test data:  0.003521531354635954\n"
     ]
    }
   ],
   "source": [
    "modelD = Sequential()\n",
    "modelD.add(Dense(8, input_dim=int(training_inputs[0].shape[0]), activation='relu'))\n",
    "modelD.add(Dense(8, activation='relu'))\n",
    "modelD.add(Dense(1, activation='relu'))\n",
    "modelD.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "modelD.fit(\n",
    "    training_inputs,\n",
    "    training_targets,\n",
    "    validation_data = (validation_inputs, validation_targets),\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    validation_steps = validation_steps,\n",
    "    callbacks=[early_stopping],\n",
    "    epochs=1000)\n",
    "testing_loss = modelD.evaluate(\n",
    "    testing_inputs,\n",
    "    testing_targets,\n",
    "    steps = testing_steps,\n",
    "    verbose = 0)\n",
    "print(\"Post-training loss on test data: \", testing_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 823 samples, validate on 103 samples\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 0.1060 - val_loss: 0.0963\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0686 - val_loss: 0.0606\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0530 - val_loss: 0.0524\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0465 - val_loss: 0.0490\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0435 - val_loss: 0.0473\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0416 - val_loss: 0.0462\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0403 - val_loss: 0.0451\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0392 - val_loss: 0.0442\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0434\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0375 - val_loss: 0.0427\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0368 - val_loss: 0.0419\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0361 - val_loss: 0.0412\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0355 - val_loss: 0.0405\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0349 - val_loss: 0.0399\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0344 - val_loss: 0.0393\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0339 - val_loss: 0.0387\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0334 - val_loss: 0.0381\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0328 - val_loss: 0.0373\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0323 - val_loss: 0.0366\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0318 - val_loss: 0.0359\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0312 - val_loss: 0.0352\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0307 - val_loss: 0.0344\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0301 - val_loss: 0.0336\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0296 - val_loss: 0.0328\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0290 - val_loss: 0.0321\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0284 - val_loss: 0.0313\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0306\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0299\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0267 - val_loss: 0.0290\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.0283\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 0.0276\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0248 - val_loss: 0.0268\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0241 - val_loss: 0.0260\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0235 - val_loss: 0.0253\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0228 - val_loss: 0.0246\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0223 - val_loss: 0.0240\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0217 - val_loss: 0.0233\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0212 - val_loss: 0.0227\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0206 - val_loss: 0.0222\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.0216\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.0211\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0206\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0201\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0197\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0193\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0189\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0185\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0181\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0177\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0173\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0170\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0166\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0162\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0159\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0152\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0149\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0145\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0142\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0135\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0131\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0124\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0118\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0110\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0107\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0105\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0103\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0097\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0095\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0093\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0091\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0090\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0088\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0086\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0085\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0083\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0062\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0062\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Post-training loss on test data:  0.004035308491438627\n"
     ]
    }
   ],
   "source": [
    "modelE = Sequential()\n",
    "modelE.add(Dense(6, input_dim=int(training_inputs[0].shape[0]), activation='relu'))\n",
    "modelE.add(Dense(6, activation='relu'))\n",
    "modelE.add(Dense(1, activation='relu'))\n",
    "modelE.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "modelE.fit(\n",
    "    training_inputs,\n",
    "    training_targets,\n",
    "    validation_data = (validation_inputs, validation_targets),\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    validation_steps = validation_steps,\n",
    "    callbacks=[early_stopping],\n",
    "    epochs=1000)\n",
    "testing_loss = modelE.evaluate(\n",
    "    testing_inputs,\n",
    "    testing_targets,\n",
    "    steps = testing_steps,\n",
    "    verbose = 0)\n",
    "print(\"Post-training loss on test data: \", testing_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
